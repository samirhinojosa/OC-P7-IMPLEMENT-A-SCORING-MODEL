{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76542308-2233-4b21-a7ff-7e89aff10511",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; background-color: #3F579F;\">\n",
    "    <h1 style=\"margin: auto; font-weight: bold; padding: 30px 30px 0px 30px; color:#fff;\" align=\"center\">Implement a scoring model - P7</h1>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 5px 30px 0px 30px;\" >\n",
    "    <h3 style=\"width: 100%; text-align: center; float: left; font-size: 24px; color:#fff;\" align=\"center\">| Notebook based on Kaggle's kernel |</h3>\n",
    "</div>\n",
    "<div style=\"display: flex; background-color: #3F579F; margin: auto; padding: 10px 30px 30px 30px;\">\n",
    "    <h4 style=\"width: 100%; text-align: center; float: left; font-size: 24px; color:#fff;\" align=\"center\">Data Scientist course - OpenClassrooms</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10f50a-d18e-4b99-bd72-9a0d5374d5f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Kernel based on <a href=\"https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features/script\", target=\"blank\">[LightGBM with Simple Features]</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb62788-3f2a-42f9-a1d5-24e9773901ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">1. Libraries</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111f5ae4-891c-465f-987b-0ea5d1a6f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "## Own specific functions \n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c067d7-d516-4e34-ad41-a36d506b17c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">2. Functions</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13eb4ea-27a7-4b77-9234-0df87a96d36f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Timer</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a06d956-9a30-4633-b049-152238a1b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b02e9-efda-4b2a-9041-db97b7bc7ac7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Categorical encoder</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd57fc-6a8b-465c-bb3d-7486545f6d13",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>One-hot encoding for categorical columns with get_dummies</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28791b34-7dcc-40fb-9c7a-17855c43de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360f41a-fd83-4e02-a2c3-fe439ed82728",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Preprocess main table</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91602c6d-7c82-4d66-8bdc-261f323cb3e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Read and merge the train and test datasets</p>\n",
    "    <p>Transforms boolean and categorical features</p>\n",
    "    <p>Add new features from existing features</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b200407c-746d-4870-9f44-dba0a586b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    \n",
    "    # Read data and merge\n",
    "    df = pd.read_csv(r\"datasets\\application_train.csv\", nrows= num_rows)\n",
    "    test_df = pd.read_csv(r\"datasets\\application_test.csv\", nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    \n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "        \n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    \n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905d049-0780-4864-b32d-d470df32ac85",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Bureau and Bureau balance</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc171184-7925-4ac4-9cff-92a295914ee1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Previous credit of applicants information in <b>others</b> finance institutions</p>\n",
    "    <p>Add new features based on Max, Min, Mean based on monthly values of previos loans</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9651f3-64f7-4c4e-839e-3e4f3d80874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    # Read data\n",
    "    bureau = pd.read_csv(r\"datasets\\bureau.csv\", nrows = num_rows)\n",
    "    bb = pd.read_csv(r\"datasets\\bureau_balance.csv\", nrows = num_rows)\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    \n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    \n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    \n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9d1c8-3f7a-431b-bbdf-b367dc3d2c3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Previous applications</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47dc73-b584-480d-8032-2e5c114e57da",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Previous credit of applicants information in <b>\"Prêt à dépenser\"</b></p>\n",
    "    <p>Add new features based on Max, Min, Mean based on monthly values of previos loans</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177d7982-96dd-4de3-bc71-a8bd592330ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    # Read data\n",
    "    prev = pd.read_csv(r\"datasets\\previous_application.csv\", nrows = num_rows)\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    \n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    \n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    \n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    \n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    \n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a103c47-47d5-4dc6-adf2-9d1dd307f411",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Pos Cash\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe3323-b347-4f4f-903d-0566da19ef8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Monthly credit (home credit, cash and consumer credits) balances of the customer</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35674408-03f1-40cf-938e-33ec49866861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    # Read data\n",
    "    pos = pd.read_csv(r\"datasets\\POS_CASH_balance.csv\", nrows = num_rows)\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    \n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    \n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    \n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del pos\n",
    "    gc.collect()\n",
    "    \n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bff388-0a1b-4a23-862c-e8703cc5025d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Installments payments</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611024bc-7262-4724-b6a7-25528de7482e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>History of payments made by the customer</p>\n",
    "    <p>Each row/sample corresponds to a payment made or late payment</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cee76da-0644-413b-8559-468677f7f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    # Read data\n",
    "    ins = pd.read_csv(r\"datasets\\installments_payments.csv\", nrows = num_rows)\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    \n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    \n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    \n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "        \n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    \n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del ins\n",
    "    gc.collect()\n",
    "    \n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f82f78-8e25-41d9-9d03-9848ba9e4a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #6D83C5;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">Credit Card Balance</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e042a-8c8b-44ce-ad27-c6b564232096",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Monthly credit card balances</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448f5108-f6e9-40a0-8ada-4bdb6d84e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    # Read data\n",
    "    cc = pd.read_csv(r\"datasets\\credit_card_balance.csv\", nrows = num_rows)\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    \n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    \n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    del cc\n",
    "    gc.collect()\n",
    "    \n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70709999-5fb9-4964-b1be-130245b8f1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">3. Initial Model</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092dff3-b61d-492f-a5f6-8c889060f7ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.1. LGBMClassifier model</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2895db03-4af4-4c43-a124-bb92df922201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
    "    \n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            #nthread=4,\n",
    "            n_jobs=-1,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            #silent=-1,\n",
    "            #verbose=-1, \n",
    "        )\n",
    "\n",
    "        #clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "        #        eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n",
    "        \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric= 'auc',\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=200),\n",
    "                          lgb.log_evaluation(period=-1)])\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    print('>> Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    \n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "        \n",
    "    #display_importances(feature_importance_df)\n",
    "    \n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89ce5e-7d1c-44e4-b419-749cc945ae18",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color:#fff; \">3.2. Feature Importance</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c7b6a2-0300-4a9d-8166-9fa406ae8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0233914-a771-4a02-932b-57728adcdb0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">4. Main function</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8d4e2-1bd4-45ab-b767-8c6522a6a59b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>Functions caller</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581122fc-e82a-4de6-873c-07059408ec47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(debug=False):  \n",
    "    \n",
    "    # To test with less data\n",
    "    num_rows = 10000 if debug else None\n",
    "    \n",
    "    with timer(\"Process Train/Test df\"):    \n",
    "        df = application_train_test(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> application_train_test\")\n",
    "        print(\"Train/Test df shape:\", df.shape)\n",
    "        #display(df.head())\n",
    "    \n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> bureau_and_balance\")\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "        #display(df.head())\n",
    "        \n",
    "        \n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> previous_applications\")\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "        #display(df.head())\n",
    "\n",
    "        \n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> pos_cash\")\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "        #display(df.head())\n",
    "        \n",
    "\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> installments_payments\")\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "        #display(df.head())\n",
    "        \n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"\\n\")\n",
    "        print(\">> credit_card_balance\")\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "        #display(df.head())\n",
    "        \n",
    "        # saving the dataset to optimize the models\n",
    "        df.to_csv(\"datasets\\df_processed.csv\", index=False)\n",
    "        \n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        print(\"\\n\")\n",
    "        print(\">> modelisation\")\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n",
    "        \n",
    "    return (df, feat_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281df6b-446d-4210-b89f-9c0350c23722",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #506AB9;\" >\n",
    "    <h2 style=\"margin: auto; padding: 20px; color:#fff; \">5. Results</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb29ba7c-68c6-436e-befe-7fb6a2afcb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "\n",
      "\n",
      ">> application_train_test\n",
      "Train/Test df shape: (356251, 248)\n",
      "Process Train/Test df - done in 6s\n",
      "\n",
      "\n",
      ">> bureau_and_balance\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 23s\n",
      "\n",
      "\n",
      ">> previous_applications\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 27s\n",
      "\n",
      "\n",
      ">> pos_cash\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 15s\n",
      "\n",
      "\n",
      ">> installments_payments\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 34s\n",
      "\n",
      "\n",
      ">> credit_card_balance\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 182s\n",
      "\n",
      "\n",
      ">> modelisation\n",
      "Starting LightGBM. Train shape: (307507, 798), test shape: (48744, 798)\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1437]\ttraining's auc: 0.876819\ttraining's binary_logloss: 0.200989\tvalid_1's auc: 0.794514\tvalid_1's binary_logloss: 0.239963\n",
      "Fold  1 AUC : 0.794514\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1570]\ttraining's auc: 0.881386\ttraining's binary_logloss: 0.199429\tvalid_1's auc: 0.791501\tvalid_1's binary_logloss: 0.235347\n",
      "Fold  2 AUC : 0.791501\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1363]\ttraining's auc: 0.874102\ttraining's binary_logloss: 0.202503\tvalid_1's auc: 0.785324\tvalid_1's binary_logloss: 0.240361\n",
      "Fold  3 AUC : 0.785324\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1652]\ttraining's auc: 0.885562\ttraining's binary_logloss: 0.197576\tvalid_1's auc: 0.796002\tvalid_1's binary_logloss: 0.234026\n",
      "Fold  4 AUC : 0.796002\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1436]\ttraining's auc: 0.876022\ttraining's binary_logloss: 0.202569\tvalid_1's auc: 0.797344\tvalid_1's binary_logloss: 0.227245\n",
      "Fold  5 AUC : 0.797344\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1262]\ttraining's auc: 0.870043\ttraining's binary_logloss: 0.204677\tvalid_1's auc: 0.785344\tvalid_1's binary_logloss: 0.236921\n",
      "Fold  6 AUC : 0.785344\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's auc: 0.869314\ttraining's binary_logloss: 0.205258\tvalid_1's auc: 0.790524\tvalid_1's binary_logloss: 0.234388\n",
      "Fold  7 AUC : 0.790524\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1425]\ttraining's auc: 0.876286\ttraining's binary_logloss: 0.201578\tvalid_1's auc: 0.78987\tvalid_1's binary_logloss: 0.238333\n",
      "Fold  8 AUC : 0.789870\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1879]\ttraining's auc: 0.894843\ttraining's binary_logloss: 0.193062\tvalid_1's auc: 0.797389\tvalid_1's binary_logloss: 0.235319\n",
      "Fold  9 AUC : 0.797389\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1575]\ttraining's auc: 0.883047\ttraining's binary_logloss: 0.198931\tvalid_1's auc: 0.789871\tvalid_1's binary_logloss: 0.23395\n",
      "Fold 10 AUC : 0.789871\n",
      "\n",
      "\n",
      ">> Full AUC score 0.791761\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'submission_file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19208/2641183552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Full model run\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_importance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_importance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19208/4132125232.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(debug)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">> modelisation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mfeat_importance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_lightgbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_importance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19208/4055312691.py\u001b[0m in \u001b[0;36mkfold_lightgbm\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SK_ID_CURR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m#display_importances(feature_importance_df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'submission_file_name' is not defined"
     ]
    }
   ],
   "source": [
    "with timer(\"Full model run\"):\n",
    "    df, feat_importance = main()\n",
    "\n",
    "print(\"\\n\")\n",
    "display_importances(feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65f893-1318-4ef8-89f4-a9022da0c274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd34efc-1585-4c29-924e-a023bcfa6816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b3d5f-f0c8-4afc-ba10-f4b91f5b95d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33280455-9c1d-4933-b31a-c9f431e66174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6d137-9cc9-4446-800e-fa32e54633e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c39e33-16f1-432f-adeb-93f9de5a95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd59281-83de-4794-a3b8-8f58e25f4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_and_pie(df[\"TARGET\"], \"Target distribution\", \" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
